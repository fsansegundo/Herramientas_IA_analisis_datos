{"cells":[{"cell_type":"markdown","source":["<p align=\"center\">\n","  <img src=\"https://apps.icai.comillas.edu/qr/generator.php?url=https%3A%2F%2Fdrive.google.com%2Ffile%2Fd%2F1ZOO9aHIWUMSmeZbf_G8bj2-2LixYzhcE%2Fview%3Fusp%3Dsharing&size=8&sumbit=Generar+QR\" width=\"350\">\n","</p>"],"metadata":{"id":"0PWQK3qcgyBn"},"id":"0PWQK3qcgyBn"},{"cell_type":"markdown","source":["# Exploratory Data Analysis with IA assistants (Gemini example)"],"metadata":{"id":"eRqdL2nYsIZc"},"id":"eRqdL2nYsIZc"},{"cell_type":"markdown","source":["# Introduction\n","\n","Our goal in this example is to illustrate the use of AI code assistants such as Google's Gemini or GitHub Copilot in any task involving code writing. We will use a data analysis problem as an example, but the same general ideas apply to many other situations.\n","\n","## Prompt guided analysis\n","\n","+ The plan is to perform an initial exploration of a given dataset by asking the assistant questions (prompts) that will result in Python code output. When we ran this experiment we did not write a single line of Python code nor did we directly modify the code. When needed, we just asked the AI assistant to rewrite the code for us.\n","\n","+ We provide below the list of prompts that we used in our experiment with this dataset. We have also included the output we got in another version of this notebook. But keep in mind that (like in the juvenile 80's books *Choose your own adventure*) different iterations of the analysis can lead you to different results. So the prompts below are more of guidelines...\n","\n","<p align=\"center\">\n","  <img src=\"https://dl.dropboxusercontent.com/scl/fi/bpbh13ecw5g7slisux1cb/Choose_Your_own_adventure_in_Data_Science.png?rlkey=gyg6os6kximsmsk0967kbgf26\" width=\"250\">\n","</p>"],"metadata":{"id":"R9e-n3IAy-xg"},"id":"R9e-n3IAy-xg"},{"cell_type":"markdown","source":["## Dataset\n","\n","The dataset we will use is the publicly available Kaggle dataset\n","\n","[**Brazilian E-Commerce Public Dataset by Olist**](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)\n","\n","Olist is an e-commerce platform from Brazil that connects sellers (often small businesses) with potential buyers across the country. providing the required logistics. The dataset consists of several tables with information about customers, orders, user reviews, products, etc. We have provided you with a link to a zip file containing all these dataset. That zip file is the starting point of the adventure, in which we assume no previous knowledge of Python data structures or libraries, not even the format of those data files!\n"],"metadata":{"id":"J9f3CB2OsQmd"},"id":"J9f3CB2OsQmd"},{"cell_type":"markdown","source":["# Let us begin\n","\n","\n","To proceed we suggest that you copy the text of the following prompt and click on the link to create code with AI in the next code cell. Then paste the prompt code and hit *Enter*.\n"],"metadata":{"id":"POi0Zn3rXxt6"},"id":"POi0Zn3rXxt6"},{"cell_type":"markdown","source":["## prompt:\n","I have a zip file at\n","https://www.dropbox.com/scl/fi/4zxiotlnzt8a6ap2hu0je/brazilian_e_commerce.zip?rlkey=h2e1u2770aq0ywltlpaapd10a&st=mtznoubo&dl=0\n","that contains several data files. I want to download it and decompress it to a subfolder called data.\n"],"metadata":{"id":"MxAEe-gDWIsj"},"id":"MxAEe-gDWIsj"},{"cell_type":"code","source":[],"metadata":{"id":"Oc2AagnD298X"},"id":"Oc2AagnD298X","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## prompt:\n","\n","I want to load all these files into python, so that e.g. olist_customers_dataset is stored as customers, and similarly for all data files whose names begin by olist_\n"],"metadata":{"id":"M7FEZZxlWVdB"},"id":"M7FEZZxlWVdB"},{"cell_type":"code","source":[],"metadata":{"id":"F_3r3FtP2-b9"},"id":"F_3r3FtP2-b9","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## prompt:\n","\n","I want to do basic exploratory analysis on the data in the customers dataframe, what should I do next?\n"],"metadata":{"id":"odhbb9WvWACj"},"id":"odhbb9WvWACj"},{"cell_type":"code","source":[],"metadata":{"id":"7CojIamW2_Ba"},"id":"7CojIamW2_Ba","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## prompt::\n","\n","How many unique values per column are there?"],"metadata":{"id":"HdmoYlb0TsXM"},"id":"HdmoYlb0TsXM"},{"cell_type":"code","source":[],"metadata":{"id":"ISgjU2v_2_yf"},"id":"ISgjU2v_2_yf","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## prompt:\n","\n","Are there duplicated rows?"],"metadata":{"id":"SJcFhD4ZV4Au"},"id":"SJcFhD4ZV4Au"},{"cell_type":"code","source":[],"metadata":{"id":"4WnSb2Z93Ank"},"id":"4WnSb2Z93Ank","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Consider other data sets"],"metadata":{"id":"zQkgdgR1P6oP"},"id":"zQkgdgR1P6oP"},{"cell_type":"markdown","source":["## prompt:\n","\n","How do I check all the other datasets at once for missing data and duplicates?\n"],"metadata":{"id":"dKkYwaLRWhHB"},"id":"dKkYwaLRWhHB"},{"cell_type":"markdown","source":["## prompt:\n","\n","In the products dataframe there are several columns with the same number of missing data. Are these missing data in the same rows of these columns?\n"],"metadata":{"id":"YmsYK1B1YWBL"},"id":"YmsYK1B1YWBL"},{"cell_type":"markdown","source":["## prompt:\n","\n","In the orders dataFrame, I have missing values. It looks like the number of missing values in some columns is correlated. How can I check if the missing values form a pattern and visualize it?\n"],"metadata":{"id":"HsAq7qTwZM4P"},"id":"HsAq7qTwZM4P"},{"cell_type":"markdown","source":["## prompt:\n","\n"," Can I do the same check for the missing values pattern and visualize it, this time in the products dataset?"],"metadata":{"id":"oTPOOxA8csof"},"id":"oTPOOxA8csof"},{"cell_type":"markdown","source":["## prompt:\n","\n","Does any of the dataframes contain date or time information?"],"metadata":{"id":"I6yOTrEmeppZ"},"id":"I6yOTrEmeppZ"},{"cell_type":"markdown","source":["## prompt:\n","\n","Can I get all the column names for the datasets?"],"metadata":{"id":"PNIM5a7sfXgm"},"id":"PNIM5a7sfXgm"},{"cell_type":"markdown","source":["## prompt:\n","\n","My next goal is to assign a customer_unique__id value with each review_id. The order_reviews dataset has a column called order_id, which I would like to use to connect it to the column with the same name in the orders dataset. Then the customer_id column in orders should be connected with the namesake column in customers.\n"],"metadata":{"id":"HojyHnGiPGHo"},"id":"HojyHnGiPGHo"},{"cell_type":"markdown","source":["## prompt:\n","\n","Is there any review_id associated with more than one user_unique_id? Is there any review_id associated with no user_unique_id?\n"],"metadata":{"id":"i-TtX0sxP7LF"},"id":"i-TtX0sxP7LF"},{"cell_type":"markdown","source":["## prompt:\n","\n","What are the columns of the resulting dataset?\n"],"metadata":{"id":"fneRYC0wQ0or"},"id":"fneRYC0wQ0or"},{"cell_type":"markdown","source":["## prompt:\n","\n","Can we repeat the merge but this time keeping all the columns in the orders dataset?"],"metadata":{"id":"dH2_suX-Q5V2"},"id":"dH2_suX-Q5V2"},{"cell_type":"markdown","source":["## prompt:\n","\n","Ok, next I would like to bring in the payment_value  information from order_payments\n"],"metadata":{"id":"38xupkg1R8x8"},"id":"38xupkg1R8x8"},{"cell_type":"markdown","source":["# prompt:\n","\n","Can I get information about the order_purchase_timestamp variable in this dataset?\n"],"metadata":{"id":"lbjLrEHoSYEI"},"id":"lbjLrEHoSYEI"},{"cell_type":"markdown","source":["# prompt:\n","\n","Can we convert that variable in the original dataset to a proper date and time type of variable?\n"],"metadata":{"id":"C4o4dPv1S0f0"},"id":"C4o4dPv1S0f0"},{"cell_type":"markdown","source":["## prompt:\n","\n","How many weeks does the order_purchase_timestamp span?"],"metadata":{"id":"z74E3RDZToor"},"id":"z74E3RDZToor"},{"cell_type":"markdown","source":["## prompt:\n","\n","Can we see a time series plot of the aggregated total value of payment_value per week?\n"],"metadata":{"id":"b17KqeqsTjjY"},"id":"b17KqeqsTjjY"},{"cell_type":"markdown","source":["## prompt:\n","\n","How could I detect seasonality in the daily series?\n"],"metadata":{"id":"M64kr9enXgJC"},"id":"M64kr9enXgJC"},{"cell_type":"markdown","source":["# Using Gemini's chat interface"],"metadata":{"id":"gPOYUlQMyWYR"},"id":"gPOYUlQMyWYR"},{"cell_type":"markdown","source":["**User:**.\n","In the last plot, of the ACF function, is there any hint of seasonality? Which frequency?"],"metadata":{"id":"Te7gcq1BUksh"},"id":"Te7gcq1BUksh"},{"cell_type":"markdown","source":["## prompt:\n","\n","I would like to fit a seasonal ARIMA model to this series. Please do not use AutoARIMA, try to find the model structure by examining the ACF and PACF of the series.\n"],"metadata":{"id":"4To6fkvXXYss"},"id":"4To6fkvXXYss"},{"cell_type":"markdown","source":["# prompt:\n","\n","Can you make diagnostic plots of the residuals for this model?\n"],"metadata":{"id":"-DAr7FmbWzz5"},"id":"-DAr7FmbWzz5"},{"cell_type":"markdown","source":["## prompt:\n","\n","I would like to conduct a Ljung-Box test to see if those residuals qualify as white noise\n"],"metadata":{"id":"-nxL6zbpWuxu"},"id":"-nxL6zbpWuxu"},{"cell_type":"markdown","source":["# Chat\n","\n","**User**.  \n","You used 10 lags for the Ljung-Box test. What is the rationale behind the choice of a number of lags for this test?"],"metadata":{"id":"BpEiydTCWW0C"},"id":"BpEiydTCWW0C"},{"cell_type":"markdown","source":["## prompt:\n","\n","There is an obvious outlier in the time series. Can you help me find the date when it happened?\n"],"metadata":{"id":"0rGX6QsEZj71"},"id":"0rGX6QsEZj71"},{"cell_type":"markdown","source":["# Chat\n","\n","**User:**  \n","Is there any reason why 2017-11-24 should be an outlier for e-commerce data in Brazil?  "],"metadata":{"id":"fN_xkbl0YDY1"},"id":"fN_xkbl0YDY1"},{"cell_type":"markdown","source":["## prompt:\n","\n","What is the distribution of review scores across different product categories?"],"metadata":{"id":"c_UkHKjfsBCL"},"id":"c_UkHKjfsBCL"},{"cell_type":"markdown","source":["# prompt:\n","\n","There are too many categories and the boxplots are too small to be informative. Can we group the categories into higher leve categories according to types of products?\n"],"metadata":{"id":"w0FEptndsIPs"},"id":"w0FEptndsIPs"},{"cell_type":"markdown","source":["## prompt:\n","\n","I think that there is a problem with the category mapping, because you are  only using English category names, while many of the categories have Portuguese names. Please use the product_category_name_translation.csv file to first translate all Portuguese category names to English and then repeat the analysis.\n"],"metadata":{"id":"lR6YlJMYsQBn"},"id":"lR6YlJMYsQBn"},{"cell_type":"markdown","source":["## prompt:\n","\n","I would like to export the reviews_with_category_and_score dataset as an Excel file and store it in the data folder\n"],"metadata":{"id":"7_JsMTfpsXRD"},"id":"7_JsMTfpsXRD"},{"cell_type":"markdown","source":["# Chat\n","\n","**User:**\n","\n","Can you make a pdf report summarizing our findings about this dataset? I would like you to include the plots that illustrate some of those findings."],"metadata":{"id":"00ybG4VgsdSE"},"id":"00ybG4VgsdSE"}],"metadata":{"kernelspec":{"display_name":"MLMIC25","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}